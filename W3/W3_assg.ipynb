{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07971759",
   "metadata": {},
   "source": [
    "# Week 3 Assignment: TF-IDF and Cosine Similarity\n",
    "\n",
    "This notebook implements a simple information retrieval system that:\n",
    "1. Loads news articles from text files\n",
    "2. Loads search queries from a queries file\n",
    "3. Computes TF-IDF weights for documents and queries\n",
    "4. Calculates cosine similarity between queries and documents\n",
    "5. Ranks documents by relevance to each query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb7c0e",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b620e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os  # For working with files and directories\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # For computing TF-IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For computing cosine similarity\n",
    "import numpy as np  # For numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1adfa",
   "metadata": {},
   "source": [
    "## Step 2: Load Articles from Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded article_1.txt\n",
      "✓ Loaded article_2.txt\n",
      "✓ Loaded article_3.txt\n",
      "✓ Loaded article_4.txt\n",
      "✓ Loaded article_5.txt\n",
      "✓ Loaded article_6.txt\n",
      "✓ Loaded article_7.txt\n",
      "✓ Loaded article_8.txt\n",
      "\n",
      "Total articles loaded: 8\n"
     ]
    }
   ],
   "source": [
    "# Function to load all article files (Following Week 2 reference style)\n",
    "def load_text_files(folder_path):\n",
    "    \"\"\"\n",
    "    Load all text files from the specified folder.\n",
    "    Returns:\n",
    "    - data: dictionary with doc_id as key and content as value\n",
    "    - doc_id_to_filename: dictionary mapping doc_id to filename\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    doc_id_to_filename = {}\n",
    "    doc_id = 0\n",
    "\n",
    "    print(f\"Scanning folder: {folder_path}\")\n",
    "    for filename in os.listdir(folder_path):\n",
    "        print(f\"Found file: {filename}\")  \n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                data[doc_id] = content\n",
    "                doc_id_to_filename[doc_id] = filename\n",
    "                print(f\"Loaded doc_id {doc_id} -> {filename}\")\n",
    "                doc_id += 1\n",
    "\n",
    "    print(f\"Total files loaded: {len(data)}\")\n",
    "    return data, doc_id_to_filename\n",
    "\n",
    "# Set the folder path (current directory)\n",
    "folder_path = r\"C:\\Users\\Swornim\\Documents\\College\\Information Retrieval\\W3\"\n",
    "\n",
    "# Load all articles\n",
    "data, doc_id_to_filename = load_text_files(folder_path)\n",
    "\n",
    "# Convert to lists for TF-IDF processing\n",
    "documents = [data[doc_id] for doc_id in sorted(data.keys())]\n",
    "document_names = [doc_id_to_filename[doc_id] for doc_id in sorted(data.keys())]\n",
    "\n",
    "print(f\"\\nReady for TF-IDF processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cc1df",
   "metadata": {},
   "source": [
    "## Step 3: Load Queries from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f29b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 5 queries from queries.txt\n",
      "\n",
      "Queries:\n",
      "1. fitness tracker technology\n",
      "2. Apple Watch smartwatch features\n",
      "3. health monitoring devices\n",
      "4. sleep quality tracking\n",
      "5. wearable technology trends\n"
     ]
    }
   ],
   "source": [
    "# Function to load queries (Following Week 2 reference style)\n",
    "def load_queries_from_file(filename='queries.txt'):\n",
    "    \"\"\"\n",
    "    Load queries from a text file.\n",
    "    Each line in the file is treated as a separate query.\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # Check if queries file exists\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            # Read all lines and remove empty lines\n",
    "            queries = [line.strip() for line in file.readlines() if line.strip()]\n",
    "        print(f\"✓ Loaded {len(queries)} queries from {filename}\")\n",
    "    else:\n",
    "        print(f\"✗ File {filename} not found\")\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# Load queries\n",
    "queries = load_queries_from_file()\n",
    "\n",
    "# Display the queries\n",
    "print(\"\\nQueries:\")\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb9d61",
   "metadata": {},
   "source": [
    "## Step 4: Compute TF-IDF Weights\n",
    "\n",
    "**What is TF-IDF?**\n",
    "- **TF** (Term Frequency): How often a word appears in a document\n",
    "- **IDF** (Inverse Document Frequency): How rare/common a word is across all documents\n",
    "- **TF-IDF**: Combines both to give higher weight to important words\n",
    "\n",
    "We'll use `TfidfVectorizer` to automatically compute TF-IDF weights for all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac54f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (8, 1000)\n",
      "  - 8 documents\n",
      "  - 1000 unique words (features)\n",
      "\n",
      "TF-IDF computation complete!\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF Vectorizer\n",
    "# This will convert text documents into TF-IDF feature vectors\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',  # Remove common English words like 'the', 'is', 'and'\n",
    "    lowercase=True,        # Convert all text to lowercase\n",
    "    max_features=1000      # Limit to top 1000 most important words\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on documents and transform them to TF-IDF vectors\n",
    "# fit_transform learns the vocabulary and computes TF-IDF values\n",
    "document_tfidf = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {document_tfidf.shape}\")\n",
    "print(f\"  - {document_tfidf.shape[0]} documents\")\n",
    "print(f\"  - {document_tfidf.shape[1]} unique words (features)\")\n",
    "print(\"\\nTF-IDF computation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e83afe",
   "metadata": {},
   "source": [
    "## Step 5: Transform Queries to TF-IDF Vectors\n",
    "\n",
    "Now we need to convert our queries into the same TF-IDF format as documents.\n",
    "We use `transform()` (not `fit_transform()`) because we want to use the same vocabulary learned from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750b0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query TF-IDF matrix shape: (5, 1000)\n",
      "  - 5 queries\n",
      "  - 1000 features (same as documents)\n",
      "\n",
      "Query transformation complete!\n"
     ]
    }
   ],
   "source": [
    "# Transform queries to TF-IDF vectors using the same vectorizer\n",
    "# This ensures queries and documents use the same vocabulary\n",
    "query_tfidf = vectorizer.transform(queries)\n",
    "\n",
    "print(f\"Query TF-IDF matrix shape: {query_tfidf.shape}\")\n",
    "print(f\"  - {query_tfidf.shape[0]} queries\")\n",
    "print(f\"  - {query_tfidf.shape[1]} features (same as documents)\")\n",
    "print(\"\\nQuery transformation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05680bd",
   "metadata": {},
   "source": [
    "## Step 6: Compute Cosine Similarity\n",
    "\n",
    "**What is Cosine Similarity?**\n",
    "- Measures how similar two vectors are\n",
    "- Values range from 0 (completely different) to 1 (identical)\n",
    "- Higher value = more similar = more relevant document\n",
    "\n",
    "We'll compute cosine similarity between each query and all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3176ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix shape: (5, 8)\n",
      "  - 5 queries\n",
      "  - 8 documents\n",
      "\n",
      "Cosine similarity computation complete!\n",
      "\n",
      "Sample similarity scores (Query 1 vs all documents):\n",
      "[0.13874896 0.02420311 0.         0.00992125 0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between queries and documents\n",
    "# Result: a matrix where each row is a query and each column is a document\n",
    "similarity_matrix = cosine_similarity(query_tfidf, document_tfidf)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "print(f\"  - {similarity_matrix.shape[0]} queries\")\n",
    "print(f\"  - {similarity_matrix.shape[1]} documents\")\n",
    "print(\"\\nCosine similarity computation complete!\")\n",
    "print(\"\\nSample similarity scores (Query 1 vs all documents):\")\n",
    "print(similarity_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51162396",
   "metadata": {},
   "source": [
    "## Step 7: Rank Documents by Similarity\n",
    "\n",
    "For each query, we'll rank documents from most relevant to least relevant based on cosine similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8279e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUERY 1: fitness tracker technology\n",
      "================================================================================\n",
      "\n",
      "Ranked Documents (by relevance):\n",
      "\n",
      "  Rank 1: article_1.txt\n",
      "           Similarity: 0.1387 ██████\n",
      "\n",
      "  Rank 2: article_2.txt\n",
      "           Similarity: 0.0242 █\n",
      "\n",
      "  Rank 3: article_4.txt\n",
      "           Similarity: 0.0099 \n",
      "\n",
      "  Rank 4: article_3.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 5: article_5.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 6: article_6.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 7: article_7.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 8: article_8.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 2: Apple Watch smartwatch features\n",
      "================================================================================\n",
      "\n",
      "Ranked Documents (by relevance):\n",
      "\n",
      "  Rank 1: article_1.txt\n",
      "           Similarity: 0.2177 ██████████\n",
      "\n",
      "  Rank 2: article_4.txt\n",
      "           Similarity: 0.1476 ███████\n",
      "\n",
      "  Rank 3: article_3.txt\n",
      "           Similarity: 0.0215 █\n",
      "\n",
      "  Rank 4: article_7.txt\n",
      "           Similarity: 0.0086 \n",
      "\n",
      "  Rank 5: article_2.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 6: article_5.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 7: article_6.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 8: article_8.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 3: health monitoring devices\n",
      "================================================================================\n",
      "\n",
      "Ranked Documents (by relevance):\n",
      "\n",
      "  Rank 1: article_1.txt\n",
      "           Similarity: 0.2016 ██████████\n",
      "\n",
      "  Rank 2: article_2.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 3: article_3.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 4: article_4.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 5: article_5.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 6: article_6.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 7: article_7.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 8: article_8.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 4: sleep quality tracking\n",
      "================================================================================\n",
      "\n",
      "Ranked Documents (by relevance):\n",
      "\n",
      "  Rank 1: article_1.txt\n",
      "           Similarity: 0.1783 ████████\n",
      "\n",
      "  Rank 2: article_2.txt\n",
      "           Similarity: 0.0152 \n",
      "\n",
      "  Rank 3: article_3.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 4: article_4.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 5: article_5.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 6: article_6.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 7: article_7.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 8: article_8.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUERY 5: wearable technology trends\n",
      "================================================================================\n",
      "\n",
      "Ranked Documents (by relevance):\n",
      "\n",
      "  Rank 1: article_2.txt\n",
      "           Similarity: 0.0475 ██\n",
      "\n",
      "  Rank 2: article_4.txt\n",
      "           Similarity: 0.0195 \n",
      "\n",
      "  Rank 3: article_1.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 4: article_3.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 5: article_5.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 6: article_6.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 7: article_7.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "  Rank 8: article_8.txt\n",
      "           Similarity: 0.0000 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to display ranked results for each query\n",
    "def display_ranked_results(queries, similarity_matrix, document_names):\n",
    "    \"\"\"\n",
    "    For each query, display documents ranked by similarity score.\n",
    "    \"\"\"\n",
    "    # Loop through each query\n",
    "    for query_idx, query in enumerate(queries):\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"QUERY {query_idx + 1}: {query}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Get similarity scores for this query with all documents\n",
    "        scores = similarity_matrix[query_idx]\n",
    "        \n",
    "        # Create pairs of (document_index, similarity_score)\n",
    "        doc_scores = [(i, scores[i]) for i in range(len(scores))]\n",
    "        \n",
    "        # Sort by similarity score in descending order (highest first)\n",
    "        # key=lambda x: x[1] means sort by the second element (the score)\n",
    "        ranked_docs = sorted(doc_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Display ranked results\n",
    "        print(f\"\\nRanked Documents (by relevance):\\n\")\n",
    "        for rank, (doc_idx, score) in enumerate(ranked_docs, 1):\n",
    "            # Create a visual bar to represent the similarity score\n",
    "            bar_length = int(score * 50)  # Scale to 50 characters max\n",
    "            bar = '█' * bar_length\n",
    "            \n",
    "            print(f\"  Rank {rank}: {document_names[doc_idx]}\")\n",
    "            print(f\"           Similarity: {score:.4f} {bar}\")\n",
    "            print()\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Display results\n",
    "display_ranked_results(queries, similarity_matrix, document_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883e93a",
   "metadata": {},
   "source": [
    "## Step 8: Summary Statistics (Optional)\n",
    "\n",
    "Let's see some overall statistics about our retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d41981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total Documents: 8\n",
      "Total Queries: 5\n",
      "Vocabulary Size: 1000\n",
      "\n",
      "\n",
      "Average Similarity Score for Each Query:\n",
      "--------------------------------------------------\n",
      "\n",
      "Query 1: fitness tracker technology\n",
      "  Average similarity: 0.0216\n",
      "  Max similarity: 0.1387\n",
      "\n",
      "Query 2: Apple Watch smartwatch features\n",
      "  Average similarity: 0.0494\n",
      "  Max similarity: 0.2177\n",
      "\n",
      "Query 3: health monitoring devices\n",
      "  Average similarity: 0.0252\n",
      "  Max similarity: 0.2016\n",
      "\n",
      "Query 4: sleep quality tracking\n",
      "  Average similarity: 0.0242\n",
      "  Max similarity: 0.1783\n",
      "\n",
      "Query 5: wearable technology trends\n",
      "  Average similarity: 0.0084\n",
      "  Max similarity: 0.0475\n",
      "\n",
      "\n",
      "Most Relevant Document-Query Pair:\n",
      "--------------------------------------------------\n",
      "Query: Apple Watch smartwatch features\n",
      "Document: article_1.txt\n",
      "Similarity Score: 0.2177\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal Documents: {len(documents)}\")\n",
    "print(f\"Total Queries: {len(queries)}\")\n",
    "print(f\"Vocabulary Size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "print(\"\\n\\nAverage Similarity Score for Each Query:\")\n",
    "print(\"-\" * 50)\n",
    "for i, query in enumerate(queries):\n",
    "    avg_similarity = np.mean(similarity_matrix[i])\n",
    "    max_similarity = np.max(similarity_matrix[i])\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    print(f\"  Average similarity: {avg_similarity:.4f}\")\n",
    "    print(f\"  Max similarity: {max_similarity:.4f}\")\n",
    "\n",
    "print(\"\\n\\nMost Relevant Document-Query Pair:\")\n",
    "print(\"-\" * 50)\n",
    "# Find the maximum similarity score in the entire matrix\n",
    "max_score = np.max(similarity_matrix)\n",
    "# Find which query and document have this maximum score\n",
    "max_position = np.where(similarity_matrix == max_score)\n",
    "query_idx = max_position[0][0]\n",
    "doc_idx = max_position[1][0]\n",
    "\n",
    "print(f\"Query: {queries[query_idx]}\")\n",
    "print(f\"Document: {document_names[doc_idx]}\")\n",
    "print(f\"Similarity Score: {max_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b314f5b",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "### How it Works:\n",
    "\n",
    "1. **Loading Data**: We read all article files and the queries file into memory\n",
    "   \n",
    "2. **TF-IDF Vectorization**: \n",
    "   - `TfidfVectorizer` converts text into numbers\n",
    "   - Each document becomes a vector of TF-IDF weights\n",
    "   - Common words (stop words) are removed\n",
    "   \n",
    "3. **Cosine Similarity**:\n",
    "   - Measures the angle between query and document vectors\n",
    "   - Score of 1 = identical, 0 = completely different\n",
    "   - Higher score = more relevant\n",
    "   \n",
    "4. **Ranking**:\n",
    "   - For each query, we sort documents by similarity score\n",
    "   - The document with highest score is ranked #1\n",
    "\n",
    "### Key Python Concepts Used:\n",
    "\n",
    "- **Lists**: To store multiple items (articles, queries)\n",
    "- **Functions**: Reusable code blocks (`load_articles()`, `load_queries()`)\n",
    "- **Loops**: `for` loops to process multiple files/queries\n",
    "- **File I/O**: Reading text files with `open()`\n",
    "- **Libraries**: sklearn for TF-IDF and cosine similarity calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
